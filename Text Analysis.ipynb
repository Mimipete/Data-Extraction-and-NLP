{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333cc714-3b04-4832-9d2f-2b866ecff154",
   "metadata": {},
   "source": [
    "# **DATA EXTARCTION AND NLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb8845-5250-4ed1-819d-fd3a0270789a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### **OBJECTIVE** \n",
    "<p>The objective of this task is to extract textual data articles from a given URL and perfrom textual<br>\n",
    "analysis to compute a set of explained variables. while ensuring that the program extracts only the article<br>\n",
    "title and the article text. It should not extract the website header, footer or anything<br>\n",
    "other than the  article text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f5262-cc80-468a-b217-92c792a070c7",
   "metadata": {},
   "source": [
    "**INSTALL AND IMPORT THE NECESSARY LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43edf0e1-21a2-42f9-8ff9-59f746a6069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from requests) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15ef306-aac5-4574-b26b-0b6fab0e3bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfe0ef5-a11b-4aea-8487-2fc83a7b35cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (3.1.4)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb01d4c-18db-4bd0-b9ca-1b963a401b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c216701-f63b-4309-a57a-97e3c919505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Input.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc712b02-0b61-432e-9a16-08ea7957dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         URL_ID                                                URL\n",
      "0    bctech2011  https://insights.blackcoffer.com/ml-and-ai-bas...\n",
      "1    bctech2012  https://insights.blackcoffer.com/streamlined-i...\n",
      "2    bctech2013  https://insights.blackcoffer.com/efficient-dat...\n",
      "3    bctech2014  https://insights.blackcoffer.com/effective-man...\n",
      "4    bctech2015  https://insights.blackcoffer.com/streamlined-t...\n",
      "..          ...                                                ...\n",
      "142  bctech2153  https://insights.blackcoffer.com/population-an...\n",
      "143  bctech2154  https://insights.blackcoffer.com/google-lsa-ap...\n",
      "144  bctech2155  https://insights.blackcoffer.com/healthcare-da...\n",
      "145  bctech2156  https://insights.blackcoffer.com/budget-sales-...\n",
      "146  bctech2157  https://insights.blackcoffer.com/amazon-buy-bo...\n",
      "\n",
      "[147 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "urls = df[[\"URL_ID\", \"URL\"]] \n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aeecae-57b2-4d94-b7ba-35b52b5f4107",
   "metadata": {},
   "source": [
    "* Use the request library to fetch the web page and BeautifulSoup to parse and extract<br>\n",
    "the article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e890e80b-97f7-439e-8bc7-0106c5e4e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3944f7-00e4-4ac9-a17b-0438d26cee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        title = soup.find(\"title\").get_text()\n",
    "        article_body = soup.find(\"article\")\n",
    "        if not article_body:\n",
    "            article_body = soup.find(\"div\", {\"class\": \"post-content\"})\n",
    "        if article_body:\n",
    "            paragraphs = [p.get_text() for p in article_body.find_all(\"p\")]\n",
    "            article_text = \" \".join(paragraphs)\n",
    "        else:\n",
    "            article_text = \"\"\n",
    "        return title, article_text \n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the article from {url}. Status code: {response.status_code}\")\n",
    "        return None, None\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9602d4-417d-4db6-b305-cad8c7f02807",
   "metadata": {},
   "source": [
    "* Save the extracted Content to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae871e0-7b98-4d23-9f33-c47b3f26c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d205d20-5533-4462-bd86-772f65cf51ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article bctech2011 saved successfully.\n",
      "Article bctech2012 saved successfully.\n",
      "Article bctech2013 saved successfully.\n",
      "Article bctech2014 saved successfully.\n",
      "Article bctech2015 saved successfully.\n",
      "Article bctech2016 saved successfully.\n",
      "Article bctech2017 saved successfully.\n",
      "Article bctech2018 saved successfully.\n",
      "Article bctech2019 saved successfully.\n",
      "Article bctech2020 saved successfully.\n",
      "Article bctech2021 saved successfully.\n",
      "Article bctech2022 saved successfully.\n",
      "Article bctech2023 saved successfully.\n",
      "Article bctech2024 saved successfully.\n",
      "Article bctech2025 saved successfully.\n",
      "Article bctech2026 saved successfully.\n",
      "Article bctech2027 saved successfully.\n",
      "Article bctech2028 saved successfully.\n",
      "Article bctech2029 saved successfully.\n",
      "Article bctech2030 saved successfully.\n",
      "Article bctech2031 saved successfully.\n",
      "Article bctech2032 saved successfully.\n",
      "Article bctech2033 saved successfully.\n",
      "Article bctech2034 saved successfully.\n",
      "Article bctech2035 saved successfully.\n",
      "Article bctech2036 saved successfully.\n",
      "Article bctech2037 saved successfully.\n",
      "Article bctech2038 saved successfully.\n",
      "Article bctech2039 saved successfully.\n",
      "Article bctech2040 saved successfully.\n",
      "Article bctech2041 saved successfully.\n",
      "Article bctech2042 saved successfully.\n",
      "Article bctech2043 saved successfully.\n",
      "Article bctech2044 saved successfully.\n",
      "Article bctech2045 saved successfully.\n",
      "Article bctech2046 saved successfully.\n",
      "Article bctech2047 saved successfully.\n",
      "Article bctech2048 saved successfully.\n",
      "Article bctech2049 saved successfully.\n",
      "Article bctech2050 saved successfully.\n",
      "Article bctech2051 saved successfully.\n",
      "Article bctech2052 saved successfully.\n",
      "Article bctech2053 saved successfully.\n",
      "Article bctech2054 saved successfully.\n",
      "Article bctech2055 saved successfully.\n",
      "Article bctech2056 saved successfully.\n",
      "Article bctech2057 saved successfully.\n",
      "Article bctech2058 saved successfully.\n",
      "Article bctech2059 saved successfully.\n",
      "Article bctech2060 saved successfully.\n",
      "Article bctech2061 saved successfully.\n",
      "Article bctech2062 saved successfully.\n",
      "Article bctech2063 saved successfully.\n",
      "Article bctech2064 saved successfully.\n",
      "Article bctech2065 saved successfully.\n",
      "Article bctech2066 saved successfully.\n",
      "Article bctech2067 saved successfully.\n",
      "Article bctech2068 saved successfully.\n",
      "Article bctech2069 saved successfully.\n",
      "Article bctech2070 saved successfully.\n",
      "Article bctech2071 saved successfully.\n",
      "Article bctech2072 saved successfully.\n",
      "Article bctech2073 saved successfully.\n",
      "Article bctech2074 saved successfully.\n",
      "Article bctech2075 saved successfully.\n",
      "Article bctech2076 saved successfully.\n",
      "Article bctech2077 saved successfully.\n",
      "Article bctech2078 saved successfully.\n",
      "Article bctech2079 saved successfully.\n",
      "Article bctech2080 saved successfully.\n",
      "Article bctech2081 saved successfully.\n",
      "Article bctech2082 saved successfully.\n",
      "Article bctech2083 saved successfully.\n",
      "Article bctech2084 saved successfully.\n",
      "Article bctech2085 saved successfully.\n",
      "Article bctech2086 saved successfully.\n",
      "Article bctech2087 saved successfully.\n",
      "Article bctech2088 saved successfully.\n",
      "Article bctech2089 saved successfully.\n",
      "Article bctech2090 saved successfully.\n",
      "Article bctech2091 saved successfully.\n",
      "Article bctech2092 saved successfully.\n",
      "Article bctech2093 saved successfully.\n",
      "Article bctech2094 saved successfully.\n",
      "Article bctech2095 saved successfully.\n",
      "Article bctech2096 saved successfully.\n",
      "Article bctech2097 saved successfully.\n",
      "Article bctech2098 saved successfully.\n",
      "Article bctech2099 saved successfully.\n",
      "Article bctech2100 saved successfully.\n",
      "Article bctech2101 saved successfully.\n",
      "Article bctech2102 saved successfully.\n",
      "Article bctech2103 saved successfully.\n",
      "Article bctech2104 saved successfully.\n",
      "Article bctech2105 saved successfully.\n",
      "Article bctech2106 saved successfully.\n",
      "Article bctech2107 saved successfully.\n",
      "Article bctech2108 saved successfully.\n",
      "Article bctech2109 saved successfully.\n",
      "Article bctech2110 saved successfully.\n",
      "Article bctech2111 saved successfully.\n",
      "Article bctech2112 saved successfully.\n",
      "Article bctech2113 saved successfully.\n",
      "Article bctech2114 saved successfully.\n",
      "Article bctech2115 saved successfully.\n",
      "Article bctech2116 saved successfully.\n",
      "Article bctech2117 saved successfully.\n",
      "Article bctech2118 saved successfully.\n",
      "Article bctech2119 saved successfully.\n",
      "Article bctech2120 saved successfully.\n",
      "Article bctech2121 saved successfully.\n",
      "Article bctech2122 saved successfully.\n",
      "Article bctech2123 saved successfully.\n",
      "Article bctech2124 saved successfully.\n",
      "Article bctech2125 saved successfully.\n",
      "Article bctech2126 saved successfully.\n",
      "Article bctech2127 saved successfully.\n",
      "Article bctech2128 saved successfully.\n",
      "Article bctech2129 saved successfully.\n",
      "Article bctech2130 saved successfully.\n",
      "Article bctech2131 saved successfully.\n",
      "Article bctech2132 saved successfully.\n",
      "Article bctech2133 saved successfully.\n",
      "Article bctech2134 saved successfully.\n",
      "Article bctech2135 saved successfully.\n",
      "Article bctech2136 saved successfully.\n",
      "Article bctech2137 saved successfully.\n",
      "Article bctech2138 saved successfully.\n",
      "Article bctech2139 saved successfully.\n",
      "Article bctech2140 saved successfully.\n",
      "Article bctech2141 saved successfully.\n",
      "Article bctech2142 saved successfully.\n",
      "Article bctech2143 saved successfully.\n",
      "Article bctech2144 saved successfully.\n",
      "Article bctech2145 saved successfully.\n",
      "Article bctech2146 saved successfully.\n",
      "Article bctech2147 saved successfully.\n",
      "Article bctech2148 saved successfully.\n",
      "Article bctech2149 saved successfully.\n",
      "Article bctech2150 saved successfully.\n",
      "Article bctech2151 saved successfully.\n",
      "Article bctech2152 saved successfully.\n",
      "Article bctech2153 saved successfully.\n",
      "Article bctech2154 saved successfully.\n",
      "Article bctech2155 saved successfully.\n",
      "Article bctech2156 saved successfully.\n",
      "Article bctech2157 saved successfully.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"extracted_articles\", exist_ok=True)\n",
    "for index, row in urls.iterrows():\n",
    "    url_id = row[\"URL_ID\"]\n",
    "    url = row[\"URL\"]\n",
    "    title, article_text = extract_article(url)\n",
    "    if title and article_text:\n",
    "        full_text = f\"{title}\\n\\n{article_text}\"\n",
    "        with open(f\"extracted_articles/{url_id}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "        print(f\"Article {url_id} saved successfully.\") \n",
    "    else:\n",
    "        print(f\"Skipping article {url_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1bff48-2975-4fcd-b15c-a9b9ab6786b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "297092b4-1211-4789-b0b6-3ee7a4a9cb52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (0.7.4)\n",
      "Requirement already satisfied: pyphen in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from textstat) (0.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\p\\anaconda 3\\envs\\new_env_name\\lib\\site-packages (from textstat) (69.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b2d7b8-c84a-4af3-8ea5-c1f547d4c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "* Unzip and Load Resources \n",
    "* Extract Text and Compute Variables \n",
    "* Save Computed Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12676030-2f49-4ae3-956b-fc1ad7271e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9cba8b0-32e1-430c-ad34-c63b2c9c7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"cmudict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5fc816-2115-4a84-9584-094e7069ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/P/Downloads/data analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c2cb01-31b7-4683-ac86-5862832f6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(os.path.join(path, \"StopWords.zip\"), \"r\") as zip_ref:\n",
    "    zip_ref.extractall(path) \n",
    "with zipfile.ZipFile(os.path.join(path, \"MasterDictionary.zip\"), \"r\") as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79b587dc-6321-4598-8961-070f46a75db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path = os.path.join(path, \"StopWords\")\n",
    "master_dict_path = os.path.join(path, \"MasterDictionary\")\n",
    "extracted_path = os.path.join(path, \"extracted_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23a54100-1a6e-4aa2-9b70-e926fdf5badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = set()\n",
    "stopwords_files = [\n",
    "    \"StopWords_Auditor.txt\",\n",
    "    \"StopWords_Currencies.txt\",\n",
    "    \"StopWords_DatesandNumbers.txt\",\n",
    "    \"StopWords_Generic.txt\",\n",
    "    \"StopWords_GenericLong.txt\",\n",
    "    \"StopWords_Geographic.txt\",\n",
    "    \"StopWords_Names.txt\"\n",
    "]\n",
    "\n",
    "for stopwords_file in stopwords_files:\n",
    "    file_path = os.path.join(stopwords_path, stopwords_file)\n",
    "    with open(file_path, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "        words = file.read().splitlines()\n",
    "        all_stopwords.update(words) \n",
    "\n",
    "all_stopwords = list(all_stopwords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59825aed-e257-49f4-8f96-ff51ace6dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = set()\n",
    "negative_words = set()\n",
    "\n",
    "positive_words_file = os.path.join(master_dict_path, \"positive-words.txt\")\n",
    "with open(positive_words_file, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "    positive_words.update(file.read().splitlines()) \n",
    "negative_words_file = os.path.join(master_dict_path, \"negative-words.txt\")\n",
    "with open(negative_words_file, \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "    negative_words.update(file.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12580c37-0db1-4d52-a72a-3ba3b045608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cmudict.dict()\n",
    "def count_syllables(word):\n",
    "    if word.lower() in d:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]][0]\n",
    "    else:\n",
    "        return 1 \n",
    "\n",
    "def is_complex_word(word):\n",
    "    return count_syllables(word) >=2\n",
    "def count_personal_pronouns(text):\n",
    "    pronouns = [\"i\", \"we\", \"my\", \"ours\", \"us\"]\n",
    "    pronouns_count = sum([text.lower().split().count(pronoun) for pronoun in pronouns])\n",
    "    return pronouns_count \n",
    "\n",
    "\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "polarity_scores = []\n",
    "subjectivity_scores = []\n",
    "average_sentence_lengths = []\n",
    "percentage_complex_words_list = []\n",
    "fog_indices = []\n",
    "average_words_per_sentence_list = []\n",
    "complex_word_counts = []\n",
    "word_counts = []\n",
    "syllables_per_word_list = []\n",
    "personal_pronouns = []\n",
    "average_word_lengths = []\n",
    "\n",
    "\n",
    "for texts_file in os.listdir(extracted_path):\n",
    "    with open(os.path.join(extracted_path, texts_file), \"r\", encoding=\"ISO-8859-1\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "        words = word_tokenize(text)\n",
    "        sentences = sent_tokenize(text)\n",
    "        filtered_text = [word.lower() for word in words if word.lower() not in all_stopwords]\n",
    "        positive_score = sum(1 for word in filtered_text if word in positive_words)\n",
    "        negative_score = sum(1 for word in filtered_text if word in negative_words) * -1\n",
    "        negative_score = abs(negative_score)\n",
    "        polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "        subjectivity_score = (positive_score + negative_score) / (len(filtered_text) + 0.000001)\n",
    "        average_sentence_length = len(filtered_text) / len(sentences) if len(sentences) > 0 else 0\n",
    "        complex_words = [word for word in filtered_text if is_complex_word(word)]\n",
    "        complex_word_count = len(complex_words)\n",
    "        percentage_complex_words = (complex_word_count / len(filtered_text)) * 100 if len(filtered_text) > 0 else 0\n",
    "        fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "        average_word_length = sum(len(word) for word in filtered_text) / len(filtered_text) if len(filtered_text) > 0 else 0\n",
    "        syllable_count = sum(count_syllables(word) for word in filtered_text)\n",
    "        syllables_per_word = syllable_count / len(filtered_text) if len(filtered_text) > 0 else 0\n",
    "        personal_pronouns_count = count_personal_pronouns(text)\n",
    "        word_count = len(filtered_text)\n",
    "        average_words_per_sentence = len(filtered_text) / len(sentences) if len(sentences) > 0 else 0\n",
    "        \n",
    "        positive_scores.append(positive_score)\n",
    "        negative_scores.append(negative_score)\n",
    "        polarity_scores.append(polarity_scores)\n",
    "        subjectivity_scores.append(subjectivity_score)\n",
    "        average_sentence_lengths.append(average_sentence_length)\n",
    "        percentage_complex_words_list.append(percentage_complex_words)\n",
    "        fog_indices.append(fog_index)\n",
    "        average_words_per_sentence_list.append(average_words_per_sentence)\n",
    "        complex_word_counts.append(complex_word_count)\n",
    "        word_counts.append(word_count)\n",
    "        syllables_per_word_list.append(syllables_per_word)\n",
    "        personal_pronouns.append(personal_pronouns_count)\n",
    "        average_word_lengths.append(average_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e128e2cb-cbe5-4e98-bd85-7b96b4518efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"URL_ID\": urls[\"URL_ID\"],\n",
    "    \"URL\": urls[\"URL\"],\n",
    "    \"POSITIVE SCORE\": positive_scores,\n",
    "    \"NEGATIVE SCORE\": negative_scores,\n",
    "    \"POLARITY SCORE\": polarity_scores,\n",
    "    \"SUBJECTIVITY SCORE\": subjectivity_scores,\n",
    "    \"AVERAGE SENTENCE LENGTH\": average_sentence_lengths,\n",
    "    \"PERCENTAGE OF COMPLEX WORDS\": percentage_complex_words_list,\n",
    "    \"FOG INDEX\": fog_indices,\n",
    "    \"AVERAGE NUMBER OF WORDS PER SENTENCE\": average_words_per_sentence_list,\n",
    "    \"COMPLEX WORD COUNT\": complex_word_counts,\n",
    "    \"WORD COUNT\": word_counts,\n",
    "    \"SYLLABLE PER WORD\": syllables_per_word_list,\n",
    "    \"PERSONAL PRONOUNS\": personal_pronouns,\n",
    "    \"AVERAGE WORD LENGTH\": average_word_length\n",
    "} \n",
    "results_df = pd.DataFrame(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f27f4ad-1ac0-422b-8d35-c77718fb77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(\"Output.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e004fcc-4c63-413a-beb1-ca91caf91dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"Output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889d68f-6a44-4bbb-9b81-726171e234f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eca478-2330-4cc7-97f4-84c543b7d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
